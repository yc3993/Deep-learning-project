{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columbia University\n",
    "### ECBM E4040 Neural Networks and Deep Learning. Fall 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECBM E4040 - Assignment 2- Task 5: Kaggle Open-ended Competition\n",
    "\n",
    "Kaggle is a platform for predictive modelling and analytics competitions in which companies and researchers post data and statisticians and data miners compete to produce the best models for predicting and describing the data.\n",
    "\n",
    "If you don't have a Kaggle account, feel free to join at [www.kaggle.com](https://www.kaggle.com). To let the CAs do the grading more conveniently, please __use Lionmail to join Kaggle__ and __use UNI as your username__.\n",
    "\n",
    "The competition is located here: https://www.kaggle.com/c/ecbm4040-assignment-2-task-5/overview.\n",
    "\n",
    "You can find detailed description about this in-class competition on the website above. Please read carefully and follow the instructions.\n",
    "\n",
    "<span style=\"color:red\">__TODO__:</span>\n",
    "1. Train a custom model for the bottle dataset classification problem. You are free to use any methods taught in the class or found by yourself on the Internet (ALWAYS provide reference to the source).\n",
    "General training methods include:\n",
    "    * Dropout\n",
    "    * Batch normalization\n",
    "    * Early stopping\n",
    "    * l1-norm & l2-norm penalization\n",
    "    \n",
    "2. You are given the test set to generate your predictions (70% public + 30% private, but you don't know which ones are public/private). Students should achieve an accuracy on the public test set of at least 70%. Two points will be deducted for each 1% below 70% accuracy threshold (i.e. 65% accuracy will have 10 points deducted). The accuracy will be shown on the public leaderboard once you submit your prediction .csv file. The private leaderboard will be released after the competition. The final ranking is based on the private leaderboard result, not the public leaderboard.\n",
    "3. \n",
    "\n",
    "    * Report your results on the Kaggle, for comparison with other students' optimal results (you can do this several times). \n",
    "    * Save your best model, using Github Classroom, at the same time when you submit the homework files into Courseworks. See instructions below. \n",
    "\n",
    "__Hint__: You can start from what you implemented in task 4. Another classic classification model named 'VGG16' can also be easily implemented. Students are allowed to use pretrained networks, and utilize transfer learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW Submission Details:\n",
    "There are three components to reporting the results of this task: \n",
    "\n",
    "**(A) Submission (up to 20 submissions each day) of the .csv prediction file throught the Kaggle platform;**. You should start doing this __VERY early__, so that students can compare their work as they are making progress with model optimization.\n",
    "\n",
    "**(B) Editing and submitting the content of this Jupyter notebook, through Courseworks; **\n",
    "(i) The code for your CNN model and for the training function. The code should be stored in __./ecbm4040/neuralnets/kaggle.py__;\n",
    "(ii) Print out your training process and accuracy __within this notebook__;\n",
    "\n",
    "**(C) Submitting your best CNN model through Github Classroom repo.**\n",
    "\n",
    "**Description of (C):** \n",
    "For this task, we will continue to use Github classroom to save your model for submission. \n",
    "\n",
    "<span style=\"color:red\">__Submission content:__ :</span>\n",
    "(i) In your Assignment 2 submission folder, create a subfolder called __KaggleModel__. Upload your best model with all the data output (for example, __MODEL.data-00000-of-00001, MODEL.meta, MODEL.index__) into the folder. \n",
    "(ii) Remember to delete any intermediate results, **we only want your best model. Do not upload any data files**. The instructors will rerun the uploaded best model and verify against the score which you reported on the Kaggle.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "files = zipfile.ZipFile('ecbm4040-assignment-2-task-5.zip', 'r')\n",
    "files.extractall(os.getcwd())\n",
    "files.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12000 images belonging to 5 classes.\n",
      "Found 3000 images belonging to 5 classes.\n",
      "Found 3500 images belonging to 1 classes.\n",
      "Batch shape=(32, 128, 128, 3), min=0.000, max=1.000\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,array_to_img,img_to_array,load_img\n",
    "\n",
    "# create generator and data augmentation\n",
    "datagen = ImageDataGenerator(validation_split=0.2, \n",
    "                             horizontal_flip=True,\n",
    "                             width_shift_range=[-20,20],\n",
    "                             rescale=1./255,\n",
    "                             rotation_range=40)\n",
    "\n",
    "# datagen = ImageDataGenerator(validation_split=0.2)\n",
    "\n",
    "# prepare an iterators for each dataset\n",
    "directory_train = 'kaggle_train_128/train_128/'\n",
    "directory_test = 'kaggle_test_128/'\n",
    "\n",
    "# train set\n",
    "train_bottle = datagen.flow_from_directory(\n",
    "    directory=directory_train, \n",
    "    target_size=(128, 128),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training')\n",
    "\n",
    "# validation set\n",
    "validation_bottle = datagen.flow_from_directory(\n",
    "    directory=directory_train,  # same directory as training data\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation') # set as validation data\n",
    "\n",
    "# test set\n",
    "test_bottle = datagen.flow_from_directory(\n",
    "    directory=directory_test,\n",
    "    target_size=(128, 128),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=1,\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    )\n",
    "\n",
    "# confirm the iterator works\n",
    "batchX, batchy = train_bottle.next()\n",
    "print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Train Your Model Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from utils.cifar_utils import load_data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375 93\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "STEP_SIZE_TRAIN = train_bottle.n // train_bottle.batch_size\n",
    "STEP_SIZE_VALID = validation_bottle.n // validation_bottle.batch_size\n",
    "print(STEP_SIZE_TRAIN, STEP_SIZE_VALID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate .csv file for Kaggle\n",
    "\n",
    "The following code snippet can be used to generate your prediction .csv file.\n",
    "\n",
    "NOTE: If your kaggle results are indicating random performance, then it's likely that the indices of your csv predictions are misaligned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# with open('predicted.csv','w') as csvfile:\n",
    "#     fieldnames = ['Id','label']\n",
    "#     writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "#     writer.writeheader()\n",
    "#     for index,l in enumerate(predicted_values_generated_by_your_model):\n",
    "#         filename = str(index) + '.png'\n",
    "#         label = str(l)\n",
    "#         writer.writerow({'Id': filename, 'label': label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model=VGG19(weights='imagenet',include_top=False) \n",
    "#I choose VGG19 as transfer learning model\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(1024,activation='relu', name='Dense1')(x)\n",
    "x=Dropout(0.7)(x)\n",
    "x=Dense(1024,activation='relu', name='Dense2')(x) \n",
    "x=Dropout(0.7)(x)\n",
    "x=Dense(512,activation='relu', name='Dense3')(x)\n",
    "preds=Dense(5,activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model=Model(inputs=base_model.input,outputs=preds,name='Kaggle_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "updated_model = Sequential()\n",
    "i = 1\n",
    "for layer in model.layers:\n",
    "    updated_model.add(layer)\n",
    "    if layer.name in ['conv2', 'conv2', 'conv4', 'conv4', 'conv4']:\n",
    "        updated_model.add(BatchNormalization(name='bn_{}'.format(i)))\n",
    "        i += 1\n",
    "\n",
    "model = updated_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:11]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers[11:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "Dense3 (Dense)               (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 22,126,661\n",
      "Trainable params: 19,801,093\n",
      "Non-trainable params: 2,325,568\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "# Adam optimizer\n",
    "# loss function will be categorical cross entropy\n",
    "# evaluation metric will be accuracy\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecbm4040/envTF24/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "375/375 [==============================] - 104s 202ms/step - loss: 1.5750 - accuracy: 0.2989 - val_loss: 2.3585 - val_accuracy: 0.5901\n",
      "Epoch 2/25\n",
      "375/375 [==============================] - 75s 200ms/step - loss: 0.8229 - accuracy: 0.7204 - val_loss: 0.6510 - val_accuracy: 0.7907\n",
      "Epoch 3/25\n",
      "375/375 [==============================] - 75s 200ms/step - loss: 0.5618 - accuracy: 0.8162 - val_loss: 0.7305 - val_accuracy: 0.7927\n",
      "Epoch 4/25\n",
      "375/375 [==============================] - 75s 201ms/step - loss: 0.4669 - accuracy: 0.8512 - val_loss: 0.5028 - val_accuracy: 0.8488\n",
      "Epoch 5/25\n",
      "375/375 [==============================] - 75s 201ms/step - loss: 0.4080 - accuracy: 0.8696 - val_loss: 0.4150 - val_accuracy: 0.8629\n",
      "Epoch 6/25\n",
      "375/375 [==============================] - 75s 200ms/step - loss: 0.3742 - accuracy: 0.8800 - val_loss: 0.5764 - val_accuracy: 0.8253\n",
      "Epoch 7/25\n",
      "375/375 [==============================] - 75s 201ms/step - loss: 0.3226 - accuracy: 0.9005 - val_loss: 0.3820 - val_accuracy: 0.8874\n",
      "Epoch 8/25\n",
      "375/375 [==============================] - 75s 201ms/step - loss: 0.2771 - accuracy: 0.9165 - val_loss: 0.8180 - val_accuracy: 0.7742\n",
      "Epoch 9/25\n",
      "375/375 [==============================] - 75s 200ms/step - loss: 0.2730 - accuracy: 0.9129 - val_loss: 0.3718 - val_accuracy: 0.8898\n",
      "Epoch 10/25\n",
      "375/375 [==============================] - 75s 200ms/step - loss: 0.2463 - accuracy: 0.9248 - val_loss: 0.5363 - val_accuracy: 0.8777\n",
      "Epoch 11/25\n",
      "375/375 [==============================] - 75s 200ms/step - loss: 0.2620 - accuracy: 0.9225 - val_loss: 0.3215 - val_accuracy: 0.9069\n",
      "Epoch 12/25\n",
      "375/375 [==============================] - 75s 201ms/step - loss: 0.2207 - accuracy: 0.9339 - val_loss: 0.6028 - val_accuracy: 0.8384\n",
      "Epoch 13/25\n",
      "375/375 [==============================] - 75s 201ms/step - loss: 0.2117 - accuracy: 0.9385 - val_loss: 0.4272 - val_accuracy: 0.8965\n",
      "Epoch 14/25\n",
      "375/375 [==============================] - 75s 199ms/step - loss: 0.2047 - accuracy: 0.9376 - val_loss: 0.3851 - val_accuracy: 0.9073\n",
      "Epoch 15/25\n",
      "375/375 [==============================] - 75s 200ms/step - loss: 0.1952 - accuracy: 0.9427 - val_loss: 0.3210 - val_accuracy: 0.9153\n",
      "Epoch 16/25\n",
      "375/375 [==============================] - 75s 199ms/step - loss: 0.1758 - accuracy: 0.9446 - val_loss: 0.3111 - val_accuracy: 0.8995\n",
      "Epoch 17/25\n",
      "375/375 [==============================] - 75s 199ms/step - loss: 0.1599 - accuracy: 0.9533 - val_loss: 0.3336 - val_accuracy: 0.9012\n",
      "Epoch 18/25\n",
      "375/375 [==============================] - 75s 200ms/step - loss: 0.1685 - accuracy: 0.9504 - val_loss: 0.2670 - val_accuracy: 0.9244\n",
      "Epoch 19/25\n",
      "375/375 [==============================] - 76s 202ms/step - loss: 0.1646 - accuracy: 0.9511 - val_loss: 0.2817 - val_accuracy: 0.9136\n",
      "Epoch 20/25\n",
      "375/375 [==============================] - 75s 201ms/step - loss: 0.1481 - accuracy: 0.9572 - val_loss: 0.5102 - val_accuracy: 0.9062\n",
      "Epoch 21/25\n",
      "375/375 [==============================] - 75s 200ms/step - loss: 0.1381 - accuracy: 0.9568 - val_loss: 0.3099 - val_accuracy: 0.9173\n",
      "Epoch 22/25\n",
      "375/375 [==============================] - 75s 200ms/step - loss: 0.1390 - accuracy: 0.9596 - val_loss: 0.3347 - val_accuracy: 0.9136\n",
      "Epoch 23/25\n",
      "375/375 [==============================] - 75s 200ms/step - loss: 0.1437 - accuracy: 0.9553 - val_loss: 0.2790 - val_accuracy: 0.9264\n",
      "Epoch 24/25\n",
      "375/375 [==============================] - 75s 201ms/step - loss: 0.1199 - accuracy: 0.9686 - val_loss: 0.4037 - val_accuracy: 0.9066\n",
      "Epoch 25/25\n",
      "375/375 [==============================] - 75s 200ms/step - loss: 0.1277 - accuracy: 0.9621 - val_loss: 0.3119 - val_accuracy: 0.9231\n"
     ]
    }
   ],
   "source": [
    "epc = 25 #number of epoches\n",
    "\n",
    "# train the model\n",
    "history = model.fit_generator(generator=train_bottle,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=validation_bottle,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecbm4040/envTF24/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3125428259372711, 0.9200268983840942]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(generator=validation_bottle,\n",
    "steps=STEP_SIZE_VALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecbm4040/envTF24/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500/3500 [==============================] - 25s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TEST=test_bottle.n//test_bottle.batch_size\n",
    "test_bottle.reset()\n",
    "pred=model.predict_generator(test_bottle,\n",
    "steps=STEP_SIZE_TEST,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_indices=np.argmax(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = (train_bottle.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: KaggleModel/KaggleModel.yc3993/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('KaggleModel/KaggleModel.yc3993')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames=[x for x in test_bottle.filenames]\n",
    "results=pd.DataFrame({\"Id\":filenames,\n",
    "                      \"label\":predictions})\n",
    "results.to_csv(\"prediction_label.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
